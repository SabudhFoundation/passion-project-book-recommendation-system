{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8521c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\shrey\\anaconda3\\lib\\site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/ef/7d/500c9ad20238fcfcb4cb9243eede163594d7020ce87bd9610c9e02771876/pip-24.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.8 MB 1.7 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.9/1.8 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 9.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-24.3.1\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "542d48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset as SurpriseDataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff7955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load a Subset of the Dataset\n",
    "# Load only the first 10,000 rows for proof of concept\n",
    "data = pd.read_csv(r'C:\\Users\\shrey\\Downloads\\Sabudh Project\\shreya.csv', low_memory=False, nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a838a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Data Preprocessing\n",
    "\n",
    "# Remove Unnamed Columns\n",
    "data = data.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbf93d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Columns to Appropriate Data Types\n",
    "data['book_id'] = data['book_id'].fillna(0).astype(int)\n",
    "data['publication_year'] = data['publication_year'].fillna(0).astype(int)\n",
    "data['publication_month'] = data['publication_month'].fillna(0).astype(int)\n",
    "data['average_rating'] = data['average_rating'].astype(float)\n",
    "data['ratings_count'] = data['ratings_count'].fillna(0).astype(int)\n",
    "data['language_code'] = data['language_code'].fillna('unknown').astype(str)\n",
    "data['country_code'] = data['country_code'].fillna('unknown').astype(str)\n",
    "data['num_pages'] = data['num_pages'].fillna(data['num_pages'].median())\n",
    "data['publisher'] = data['publisher'].fillna('unknown')\n",
    "data['text_reviews_count'] = data['text_reviews_count'].fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dca47729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Create is_new_release feature\n",
    "data['is_new_release'] = (2023 - data['publication_year']).apply(lambda x: 1 if x <= 1 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc103878",
   "metadata": {},
   "source": [
    "Feature Engineering:\n",
    "\n",
    "Added a new column is_new_release to indicate if a book is a recent release.\n",
    "Focused on relevant features like text_reviews_count, average_rating, num_pages, publication_year, and language_code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67ec52f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from ratings\n",
    "data = data[(data['average_rating'] >= 1) & (data['average_rating'] <= 5)]\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6daf3a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   isbn                  10000 non-null  object \n",
      " 1   text_reviews_count    10000 non-null  int32  \n",
      " 2   series                10000 non-null  object \n",
      " 3   country_code          10000 non-null  object \n",
      " 4   language_code         10000 non-null  object \n",
      " 5   popular_shelves       10000 non-null  object \n",
      " 6   asin                  0 non-null      float64\n",
      " 7   is_ebook              10000 non-null  bool   \n",
      " 8   average_rating        10000 non-null  float64\n",
      " 9   kindle_asin           3550 non-null   object \n",
      " 10  similar_books         10000 non-null  object \n",
      " 11  description           10000 non-null  object \n",
      " 12  format                9127 non-null   object \n",
      " 13  link                  10000 non-null  object \n",
      " 14  authors               10000 non-null  object \n",
      " 15  publisher             10000 non-null  object \n",
      " 16  num_pages             10000 non-null  float64\n",
      " 17  publication_day       8234 non-null   float64\n",
      " 18  isbn13                9776 non-null   float64\n",
      " 19  publication_month     10000 non-null  int32  \n",
      " 20  edition_information   372 non-null    object \n",
      " 21  publication_year      10000 non-null  int32  \n",
      " 22  url                   10000 non-null  object \n",
      " 23  image_url             10000 non-null  object \n",
      " 24  book_id               10000 non-null  int32  \n",
      " 25  ratings_count         10000 non-null  int32  \n",
      " 26  work_id               10000 non-null  float64\n",
      " 27  title                 10000 non-null  object \n",
      " 28  title_without_series  10000 non-null  object \n",
      "dtypes: bool(1), float64(6), int32(5), object(17)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "       text_reviews_count  asin  average_rating     num_pages  \\\n",
      "count        10000.000000   0.0    10000.000000  10000.000000   \n",
      "mean            29.976900   NaN        3.886441     87.951100   \n",
      "std            133.130762   NaN        0.354101    101.578482   \n",
      "min              0.000000   NaN        1.710000      0.000000   \n",
      "25%              3.000000   NaN        3.680000     32.000000   \n",
      "50%              7.000000   NaN        3.920000     40.000000   \n",
      "75%             19.000000   NaN        4.120000    128.000000   \n",
      "max           4167.000000   NaN        5.000000   3210.000000   \n",
      "\n",
      "       publication_day        isbn13  publication_month  publication_year  \\\n",
      "count      8234.000000  9.776000e+03       10000.000000      10000.000000   \n",
      "mean          9.750182  9.767194e+12           5.248500       1844.823000   \n",
      "std           9.914913  3.567082e+11           3.758106        578.207708   \n",
      "min           1.000000  7.728218e+09           0.000000          0.000000   \n",
      "25%           1.000000  9.780440e+12           2.000000       1997.000000   \n",
      "50%           5.500000  9.780760e+12           5.000000       2006.000000   \n",
      "75%          17.000000  9.781480e+12           9.000000       2012.000000   \n",
      "max          31.000000  9.790000e+12          12.000000      21017.000000   \n",
      "\n",
      "            book_id  ratings_count       work_id  \n",
      "count  1.000000e+04   10000.000000  1.000000e+04  \n",
      "mean   9.039761e+06     485.006600  1.192313e+07  \n",
      "std    9.494647e+06    4818.832612  1.593344e+07  \n",
      "min    2.360000e+02       0.000000  1.150000e+02  \n",
      "25%    1.138091e+06      13.000000  1.038542e+06  \n",
      "50%    5.206266e+06      37.000000  2.768060e+06  \n",
      "75%    1.583515e+07     122.000000  1.911239e+07  \n",
      "max    3.641296e+07  276439.000000  5.833838e+07  \n"
     ]
    }
   ],
   "source": [
    "# Check the final structure of the data\n",
    "print(data.info())\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46754871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
      "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
      "       'similar_books', 'description', 'format', 'link', 'authors',\n",
      "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
      "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
      "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
      "       'title_without_series'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea672a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic user_id column\n",
    "import numpy as np\n",
    "num_users = 100  # Number of synthetic users\n",
    "data['user_id'] = np.random.randint(1, num_users + 1, size=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0295a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build the Recommender System\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data into the Surprise format\n",
    "dataset = SurpriseDataset.load_from_df(data[['user_id', 'book_id', 'average_rating']], reader)\n",
    "\n",
    "# Split the dataset\n",
    "trainset, testset = train_test_split(dataset, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7babb6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x182a0a9f280>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the SVD model\n",
    "model = SVD()\n",
    "model.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "668c4251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3619\n",
      "RMSE:  0.36188167034851026\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.test(testset)\n",
    "print(\"RMSE: \", accuracy.rmse(predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae808c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff3c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Recommendations\n",
    "\n",
    "def get_recommendations(model, user_id, n_recommendations=5):\n",
    "    all_book_ids = data['book_id'].unique()\n",
    "    rated_books = data[data['user_id'] == user_id]['book_id']\n",
    "\n",
    "    to_predict = [book for book in all_book_ids if book not in rated_books]\n",
    "\n",
    "    predictions = [model.predict(user_id, book) for book in to_predict]\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "\n",
    "    recommended_books = predictions[:n_recommendations]\n",
    "    return [(pred.iid, pred.est) for pred in recommended_books]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d518daf",
   "metadata": {},
   "source": [
    "Model Training: The code uses the SVD algorithm from the Surprise library to train the recommender system.\n",
    "\n",
    "Recommendations: The function get_recommendations generates book recommendations based on the predicted ratings for books that the user has not yet rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e090cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for synthetic user 33: [(3116884, 4.243889914616535), (14070444, 4.231791759124515), (2775591, 4.221983167485723), (16718170, 4.209368087000669), (18984670, 4.191291333821746)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage for a synthetic user_id\n",
    "user_id = np.random.randint(1, num_users + 1)  # Randomly choose a user ID\n",
    "recommendations = get_recommendations(model, user_id)\n",
    "print(f\"Recommendations for synthetic user {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb1a5b",
   "metadata": {},
   "source": [
    "The output received is a list of recommended books for the synthetic user (in this case, user ID 33). Each entry in the list provides two pieces of information:\n",
    "\n",
    "- Book ID: The first element in each tuple is the ID of the recommended book. This ID corresponds to a specific book in dataset.\n",
    "\n",
    "- Estimated Rating: The second element is the estimated rating that the model predicts the synthetic user would give to that book. This rating is based on the user's past interactions and the characteristics of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb227d02",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "- Book IDs: Can look up these IDs in original dataset to find out more details about each book (e.g., title, author, genre, etc.).\n",
    "- Estimated Ratings: Higher values indicate that the model predicts the user will enjoy these books more. For example, a predicted rating of 4.208 suggests that the model believes the user will rate that book quite positively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ebd7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       book_id                                              title  \\\n",
      "1936  16718170         The Third Wheel (Diary of a Wimpy Kid, #7)   \n",
      "3196  14070444  Viaje al Bosque: un maletín lleno de Historias...   \n",
      "5790  18984670                      How to Steal a Dragon's Sword   \n",
      "8168   3116884                 Curious George Learns the Alphabet   \n",
      "9518   2775591                            The Teddy Bears' Picnic   \n",
      "\n",
      "                                                authors  average_rating  \n",
      "1936              [{'author_id': '221559', 'role': ''}]            4.20  \n",
      "3196  [{'author_id': '288388', 'role': ''}, {'author...            4.83  \n",
      "5790  [{'author_id': '23894', 'role': ''}, {'author_...            4.43  \n",
      "8168              [{'author_id': '967839', 'role': ''}]            4.23  \n",
      "9518  [{'author_id': '60143', 'role': ''}, {'author_...            4.22  \n"
     ]
    }
   ],
   "source": [
    "recommended_ids = [rec[0] for rec in recommendations]\n",
    "recommended_books = data[data['book_id'].isin(recommended_ids)]\n",
    "print(recommended_books[['book_id', 'title', 'authors', 'average_rating']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a357",
   "metadata": {},
   "source": [
    "The output received is a DataFrame that provides details about the recommended books. Here’s a breakdown of each column and what it represents:\n",
    "\n",
    "- The number in output refers to the index of the row in the DataFrame that contains the details for the recommended book. It indicates that this particular book is located at that position of the DataFrame.\n",
    "\n",
    "\n",
    "- book_id: This is the unique identifier for each book in dataset. It corresponds to the IDs received in the recommendation output.\n",
    "\n",
    "- title: This is the title of the book. It provides context about what each recommended book is.\n",
    "\n",
    "- authors: This column contains information about the authors of the book. In the output, it appears to be a list of dictionaries, where each dictionary contains the author’s ID and potentially their role (like primary author, editor, etc.). For a clearer view, we can extract just the author names.\n",
    "\n",
    "- average_rating: This represents the average rating that the book has received from all users in the dataset. It gives an indication of how well-received the book is generally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74069d",
   "metadata": {},
   "source": [
    "Further Feature Engineering: Can further refine features based on insights from EDA or additional data sources.\n",
    "Experiment with Models: Trying different algorithms (like KNN, NMF) available in the Surprise library to see which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5577b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
